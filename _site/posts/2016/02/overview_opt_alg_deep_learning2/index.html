

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>An Overview on Optimization Algorithms in Deep Learning 2 - Taihong Xiao</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Taihong Xiao">
<meta property="og:title" content="An Overview on Optimization Algorithms in Deep Learning 2">


  <link rel="canonical" href="http://localhost:4000/posts/2016/02/overview_opt_alg_deep_learning2/">
  <meta property="og:url" content="http://localhost:4000/posts/2016/02/overview_opt_alg_deep_learning2/">



  <meta property="og:description" content="$$\DeclareMathOperator{\E}{E}$$$$\DeclareMathOperator{\RMS}{RMS}$$">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2016-02-04T00:00:00-08:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Taihong Xiao",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Taihong Xiao Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
          jax: ["input/TeX", "output/HTML-CSS"],
                tex2jax: {
                        inlineMath: [ ['$', '$'] ],
                                displayMath: [ ['$$', '$$'] ],
                                        processEscapes: true,
                                                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                                                      }
                                                            //,
                                                                  //displayAlign: "left",
                                                                        //displayIndent: "2em"
                                                                            });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>



<meta http-equiv="cleartype" content="on">


    

<!-- start custom head snippets -->


<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<!-- mathjax config similar to math.stackexchange -->
<!-- <script type="text/x-mathjax-config"> -->
<!-- MathJax.Hub.Config({ -->
<!--     jax: ["input/TeX", "output/HTML-CSS"], -->
<!--         tex2jax: { -->
<!--                 inlineMath: [ ['$', '$'] ], -->
<!--                 displayMath: [ ['$$', '$$']], -->
<!--                 processEscapes: true, -->
<!--                 skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] -->
<!--                 }, -->
<!--                 messageStyle: "none", -->
<!--                 "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] } -->
<!-- }); -->
<!-- </script> -->
<!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->


<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Taihong Xiao</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/talks/">Talks</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">CV</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/taihong.png" class="author__avatar" alt="Taihong Xiao">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Taihong Xiao</h3>
    <p class="author__bio">Master Student at Peking University</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Beijing</li>
      
      
      
      
        <li><a href="mailto:xiaotaihong@pku.edu.cn"><i class="fa fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
      
      
      
      
        <li><a href="https://www.facebook.com/ulton.prinsphield"><i class="fa fa-fw fa-facebook-square" aria-hidden="true"></i> Facebook</a></li>
      
      
      
        <li><a href="https://www.linkedin.com/in/taihong-xiao-82459157"><i class="fa fa-fw fa-linkedin-square" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
      
        <li><a href="https://github.com/prinsphield"><i class="fa fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=Op_tr2IAAAAJ"><i class="ai ai-google-scholar-square ai-fw"></i> Google Scholar</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="An Overview on Optimization Algorithms in Deep Learning 2">
    <meta itemprop="description" content="$$\DeclareMathOperator{\E}{E}$$$$\DeclareMathOperator{\RMS}{RMS}$$">
    <meta itemprop="datePublished" content="February 04, 2016">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">An Overview on Optimization Algorithms in Deep Learning 2
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  3 minute read
	
</p>
          
        

        
        <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2016-02-04T00:00:00-08:00">February 04, 2016</time> </p>
        


        <!--  -->

        </header>
      

      <section class="page__content" itemprop="text">
        <div style="display:none">
$$\DeclareMathOperator{\E}{E}$$
$$\DeclareMathOperator{\RMS}{RMS}$$
</div>

<p>In the <a href="/posts/2016/02/overview_opt_alg_deep_learning1/">last article</a>,
I have introduced several basic optimization algorithms. However, those algorithms rely on the hyperparameter - the learning rate $\eta$ that has a significant impact on model performance. Though the use of momentum can go some way to alleviate these issues, it does so by introducing another hyperparameter $\rho$ that may be just as difficult to set as the original learning rate. In the face of this, itâ€™s naturally to find other way to set learning rate automatically.</p>

<h2 id="adagrad">AdaGrad</h2>

<p>AdaGrad algorithm adapts the learning rates of all model parameters by scaling them inversely proportional to the accumulated sum of squared partial derivatives over all training iterations. The update rule for AdaGrad is as follows:</p>

<script type="math/tex; mode=display">\Delta \theta = -{\eta\over \sqrt{\sum_{\tau=1}^t g_{\tau}^2}}g_t</script>

<p>Here the denominator computes the $l^2$ norm of all previous gradients on a per-dimension basis and $\eta$ is a global learning rate shared by all dimensions.</p>

<p><img src="/extra/optimization/AdaGrad.jpg" /></p>

<p>The AdaGrad algorithm relies on the first order information but has some properties of second order methods and annealing. Since the dynamic rate grows with the inverse of gradient magnitudes, large gradients have smaller learning rates and small gradients have large learning rates. This nice property, as in second order methods, makes progress along each dimension even out over time. This is very useful in deep learning model, because the scale of gradients in each layer varies by several orders of magnitude. Additionally, the denominator of the scaling coefficient has the same effects as annealing, reducing the learning rate over time.</p>

<h2 id="rmsprop">RMSprop</h2>

<p>The RMSprop algorithm addresses the deficiency of AdaGrad by changing the gradient accumulation into an exponentially weighted moving average. In deep networks, directions in parameter space with strong partial derivatives may flatten out early, so RMSprop introduces a new hyperparameter $\rho$ that controls the length scale of the moving average to prevent that from happening.</p>

<p><img src="/extra/optimization/RMSprop.jpg" /></p>

<p>RMSprop with Nesterov momentum algorithm is shown below.</p>

<p><img src="/extra/optimization/RMSprop-Nesterov-momentum.jpg" /></p>

<h2 id="adam">Adam</h2>

<p>Adam is another adaptive learning rate algorithm presented below. It can been seen as a combination of RMSprop and momentum. Adam algorithm includes bias corrections to the estimates of both the first order moment and second order moment to prevent parameters from high bias early in training.</p>

<p><img src="/extra/optimization/Adam.jpg" /></p>

<h2 id="adadelta">AdaDelta</h2>

<p>This method was derived from AdaGrad in order to improve upon the two main drawbacks of the method:</p>

<ol>
  <li>the continual decay of learning rates throughout training;</li>
  <li>the need for a manually selected global learning rate.</li>
</ol>

<p>Instead of accumulating the sum of squared gradients over all time, we restricted the window of past gradients that are accumulated to be some fixed size $w$ instead of size $t$ where $t$ is the current iteration as in AdaGrad. Since storing $w$ previous squared gradients is inefficient, our methods implements this accumulation as an exponentially decaying average of the squared gradients. Assume at time $t$ this running average is $\E(g^2)_t$ then we compute</p>

<script type="math/tex; mode=display">\E(g^2)_t = \rho \E(g^2)_{t-1} +(1-\rho)g_t^2</script>

<p>Since we require the square root of this quantity in the parameter updates, this effectively becomes the RMS of previous squared gradients up to time $t$</p>

<script type="math/tex; mode=display">\RMS(g)_t=\sqrt{\E(g^2)_t+\epsilon}</script>

<p>The resulting parameter update is then</p>

<script type="math/tex; mode=display">\Delta\theta = -{\eta\over \RMS(g)_t}g_t \tag 1\label{eq-1}</script>

<p>Since the RMS of the previous gradients is already presented in the denominator in \eqref{eq-1}, we considered a measure of the $\Delta\theta$ quantity in the numerator. By computing the exponentially decaying RMS over a window of size $w$ of previous $\Delta\theta$ to give the AdaDelta method:</p>

<script type="math/tex; mode=display">\Delta\theta=-{\RMS(\Delta\theta)_{t-1}\over \RMS(g)_t}g_t</script>

<p>where the same constant $\epsilon$ is added to the numerator RMS as well to ensure progress continues to be made even if previous updates becomes small.</p>

<p><img src="/extra/optimization/AdaDelta.jpg" /></p>

<p>Extra boon: A pdf-format cheet sheet containing all these algorithms could be downloaded <a href="/extra/algorithms.pdf">here</a> for reference.</p>

<h2 id="reference">Reference</h2>


        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#deep-learning" class="page__taxonomy-item" rel="tag">Deep Learning</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#optimization" class="page__taxonomy-item" rel="tag">Optimization</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/posts/2016/02/overview_opt_alg_deep_learning2/" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/posts/2016/02/overview_opt_alg_deep_learning2/" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=http://localhost:4000/posts/2016/02/overview_opt_alg_deep_learning2/" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/posts/2016/02/overview_opt_alg_deep_learning2/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/posts/2016/02/overview_opt_alg_deep_learning1/" class="pagination--pager" title="An Overview on Optimization Algorithms in Deep Learning 1
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    </script>

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    

    
      <li><a href="https://facebook.com/"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i> Facebook</a></li>
    
    
      <li><a href="https://www.linkedin.com/in/taihong-xiao-82459157"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i> Linkedin</a></li>
    
    
      <li><a href="http://github.com/prinsphield"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2017 Taihong Xiao. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>







  </body>
</html>

